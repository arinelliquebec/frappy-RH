# ğŸ§  Frappy IA - IntegraÃ§Ã£o com Dados Reais do Sistema

> **Guia avanÃ§ado** para fazer o Frappy IA ler e processar dados reais do FrappYOU
> **Objetivo**: IA contextualizada que responde com dados precisos do banco

---

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Arquitetura de Dados](#arquitetura-de-dados)
3. [Context Injection](#context-injection)
4. [Function Calling](#function-calling)
5. [RAG - Base de Conhecimento](#rag-base-de-conhecimento)
6. [Cache Inteligente](#cache-inteligente)

---

## ğŸ¯ VisÃ£o Geral

### Problema Atual

O chat bÃ¡sico do Azure OpenAI **nÃ£o tem acesso** aos dados do sistema:
- âŒ NÃ£o sabe quantas fÃ©rias o usuÃ¡rio tem
- âŒ NÃ£o conhece o saldo do banco de horas
- âŒ NÃ£o vÃª os cursos disponÃ­veis
- âŒ NÃ£o acessa polÃ­ticas da empresa

### SoluÃ§Ã£o: 3 EstratÃ©gias

1. **Context Injection** - Injetar dados no system prompt
2. **Function Calling** - IA chama funÃ§Ãµes do backend
3. **RAG** - Busca em base de conhecimento

---

## ğŸ—ï¸ Arquitetura de Dados

### Fluxo Completo

```
UsuÃ¡rio: "Quantas fÃ©rias tenho?"
    â†“
Backend recebe pergunta
    â†“
Identifica contexto necessÃ¡rio (fÃ©rias)
    â†“
Busca dados no banco SQL
    â†“
Injeta dados no prompt
    â†“
Envia para Azure OpenAI
    â†“
IA responde com dados reais
    â†“
Retorna para usuÃ¡rio
```

---

## ğŸ’‰ Context Injection (EstratÃ©gia 1)

### Conceito

Buscar dados do banco **antes** de chamar a IA e injetar no system prompt.

### ImplementaÃ§Ã£o Completa

```go
// services/chat_context.go
package services

import (
    "fmt"
    "time"
    "github.com/frappyou/backend/models"
)

type ChatContext struct {
    UserData      *models.User
    VacationData  *VacationContext
    ClockData     *ClockContext
    PayrollData   *PayrollContext
    CoursesData   *CoursesContext
    TeamData      *TeamContext
}

type VacationContext struct {
    Balance        int       `json:"balance"`
    Period         string    `json:"period"`
    Deadline       time.Time `json:"deadline"`
    NextVacation   *models.Vacation `json:"next_vacation"`
    PendingRequest bool      `json:"pending_request"`
}

type ClockContext struct {
    TodayEntries   []models.ClockEntry `json:"today_entries"`
    MonthHours     int                 `json:"month_hours"`
    ExpectedHours  int                 `json:"expected_hours"`
    BankBalance    int                 `json:"bank_balance"` // minutos
    LastEntry      *models.ClockEntry  `json:"last_entry"`
}

type PayrollContext struct {
    LastPayroll    *models.Payroll `json:"last_payroll"`
    YTDEarnings    float64         `json:"ytd_earnings"`
    AvgSalary      float64         `json:"avg_salary"`
}

type CoursesContext struct {
    EnrolledCourses []models.Course `json:"enrolled"`
    AvailableCourses []models.Course `json:"available"`
    CompletedCount  int             `json:"completed_count"`
    InProgressCount int             `json:"in_progress_count"`
}

type TeamContext struct {
    Manager      *models.User   `json:"manager"`
    TeamMembers  []models.User  `json:"team_members"`
    Department   string         `json:"department"`
}
```

// Buscar contexto completo do usuÃ¡rio
func (s *ChatService) GetUserContext(userID string) (*ChatContext, error) {
    ctx := &ChatContext{}

    // 1. Dados bÃ¡sicos do usuÃ¡rio
    user, err := getUserByID(userID)
    if err != nil {
        return nil, err
    }
    ctx.UserData = user

    // 2. Dados de fÃ©rias
    ctx.VacationData = &VacationContext{
        Balance:  getVacationBalance(userID),
        Period:   getVacationPeriod(userID),
        Deadline: getVacationDeadline(userID),
        NextVacation: getNextVacation(userID),
        PendingRequest: hasPendingVacationRequest(userID),
    }

    // 3. Dados de ponto
    ctx.ClockData = &ClockContext{
        TodayEntries:  getTodayClockEntries(userID),
        MonthHours:    getMonthWorkedHours(userID),
        ExpectedHours: getExpectedHours(userID),
        BankBalance:   getHourBankBalance(userID),
        LastEntry:     getLastClockEntry(userID),
    }

    // 4. Dados de folha
    ctx.PayrollData = &PayrollContext{
        LastPayroll: getLastPayroll(userID),
        YTDEarnings: getYTDEarnings(userID),
        AvgSalary:   getAvgSalary(userID),
    }

    // 5. Dados de cursos
    ctx.CoursesData = &CoursesContext{
        EnrolledCourses:  getEnrolledCourses(userID),
        AvailableCourses: getAvailableCourses(user.Department),
        CompletedCount:   getCompletedCoursesCount(userID),
        InProgressCount:  getInProgressCoursesCount(userID),
    }

    // 6. Dados da equipe
    ctx.TeamData = &TeamContext{
        Manager:     getManager(userID),
        TeamMembers: getTeamMembers(userID),
        Department:  user.Department,
    }

    return ctx, nil
}
```

// System prompt com contexto completo
func (s *ChatService) getSystemPromptWithContext(userID string) string {
    context, err := s.GetUserContext(userID)
    if err != nil {
        // Fallback para prompt bÃ¡sico
        return s.getBasicSystemPrompt(userID)
    }

    prompt := fmt.Sprintf(`VocÃª Ã© o Frappy IA, assistente virtual do FrappYOU.

## DADOS DO COLABORADOR

### InformaÃ§Ãµes Pessoais
- Nome: %s
- Cargo: %s
- Departamento: %s
- Data de admissÃ£o: %s
- Tempo de casa: %s

### FÃ©rias
- Saldo disponÃ­vel: %d dias
- PerÃ­odo aquisitivo: %s
- Prazo para usar: %s
- PrÃ³ximas fÃ©rias agendadas: %s
- SolicitaÃ§Ã£o pendente: %v

### Ponto EletrÃ´nico (Hoje)
- Registros de hoje: %d
- Horas trabalhadas no mÃªs: %dh %dmin
- Horas esperadas: %dh
- Banco de horas: %s (%dh %dmin)
- Ãšltimo registro: %s

### Folha de Pagamento
- Ãšltimo holerite: %s
- SalÃ¡rio lÃ­quido: R$ %.2f
- Ganhos no ano: R$ %.2f

### Cursos e Desenvolvimento
- Cursos em andamento: %d
- Cursos concluÃ­dos: %d
- Cursos disponÃ­veis: %d

### Equipe
- Gestor: %s
- Membros da equipe: %d pessoas
- Departamento: %s

## INSTRUÃ‡Ã•ES

1. Use SEMPRE os dados acima para responder perguntas
2. Seja especÃ­fico e preciso com nÃºmeros e datas
3. Se o usuÃ¡rio perguntar sobre dados que vocÃª tem, responda diretamente
4. Se nÃ£o tiver o dado, seja honesto e sugira contatar RH
5. Use emojis para deixar a conversa mais amigÃ¡vel
6. Formate datas no padrÃ£o brasileiro (DD/MM/YYYY)
7. Formate valores monetÃ¡rios com R$ e 2 casas decimais

## EXEMPLOS DE RESPOSTAS

Pergunta: "Quantas fÃ©rias tenho?"
Resposta: "VocÃª tem %d dias de fÃ©rias disponÃ­veis! ğŸ“… Seu perÃ­odo aquisitivo Ã© %s e vocÃª precisa usar atÃ© %s. %s"

Pergunta: "Como estÃ¡ meu banco de horas?"
Resposta: "Seu banco de horas estÃ¡ %s com %dh %dmin. VocÃª trabalhou %dh %dmin este mÃªs e o esperado era %dh. %s"

Responda sempre em portuguÃªs do Brasil.`,
        // Dados pessoais
        context.UserData.Name,
        context.UserData.Position,
        context.UserData.Department,
        context.UserData.HireDate.Format("02/01/2006"),
        calculateTimeInCompany(context.UserData.HireDate),

        // FÃ©rias
        context.VacationData.Balance,
        context.VacationData.Period,
        context.VacationData.Deadline.Format("02/01/2006"),
        formatNextVacation(context.VacationData.NextVacation),
        context.VacationData.PendingRequest,

        // Ponto
        len(context.ClockData.TodayEntries),
        context.ClockData.MonthHours/60,
        context.ClockData.MonthHours%60,
        context.ClockData.ExpectedHours/60,
        formatBankBalance(context.ClockData.BankBalance),
        abs(context.ClockData.BankBalance)/60,
        abs(context.ClockData.BankBalance)%60,
        formatLastEntry(context.ClockData.LastEntry),

        // Folha
        context.PayrollData.LastPayroll.Month.Format("01/2006"),
        context.PayrollData.LastPayroll.NetSalary,
        context.PayrollData.YTDEarnings,

        // Cursos
        context.CoursesData.InProgressCount,
        context.CoursesData.CompletedCount,
        len(context.CoursesData.AvailableCourses),

        // Equipe
        context.TeamData.Manager.Name,
        len(context.TeamData.TeamMembers),
        context.TeamData.Department,

        // Exemplos dinÃ¢micos
        context.VacationData.Balance,
        context.VacationData.Period,
        context.VacationData.Deadline.Format("02/01/2006"),
        getVacationAdvice(context.VacationData),
        getBankBalanceStatus(context.ClockData.BankBalance),
        abs(context.ClockData.BankBalance)/60,
        abs(context.ClockData.BankBalance)%60,
        context.ClockData.MonthHours/60,
        context.ClockData.MonthHours%60,
        context.ClockData.ExpectedHours/60,
        getBankAdvice(context.ClockData.BankBalance),
    )

    return prompt
}
```

// FunÃ§Ãµes auxiliares de formataÃ§Ã£o
func calculateTimeInCompany(hireDate time.Time) string {
    duration := time.Since(hireDate)
    years := int(duration.Hours() / 24 / 365)
    months := int(duration.Hours()/24/30) % 12

    if years > 0 {
        return fmt.Sprintf("%d anos e %d meses", years, months)
    }
    return fmt.Sprintf("%d meses", months)
}

func formatNextVacation(vacation *models.Vacation) string {
    if vacation == nil {
        return "Nenhuma fÃ©rias agendada"
    }
    return fmt.Sprintf("%s a %s (%d dias)",
        vacation.StartDate.Format("02/01/2006"),
        vacation.EndDate.Format("02/01/2006"),
        vacation.Days,
    )
}

func formatBankBalance(minutes int) string {
    if minutes >= 0 {
        return "positivo"
    }
    return "negativo"
}

func formatLastEntry(entry *models.ClockEntry) string {
    if entry == nil {
        return "Nenhum registro hoje"
    }
    return fmt.Sprintf("%s Ã s %s",
        translateEntryType(entry.Type),
        entry.Timestamp.Format("15:04"),
    )
}

func translateEntryType(entryType string) string {
    types := map[string]string{
        "entrada":      "Entrada",
        "saida":        "SaÃ­da",
        "pausa_inicio": "InÃ­cio de pausa",
        "pausa_fim":    "Fim de pausa",
    }
    return types[entryType]
}

func getVacationAdvice(vacation *VacationContext) string {
    daysUntilDeadline := int(time.Until(vacation.Deadline).Hours() / 24)

    if daysUntilDeadline < 30 {
        return "âš ï¸ ATENÃ‡ÃƒO: VocÃª precisa usar suas fÃ©rias em menos de 30 dias!"
    }
    if daysUntilDeadline < 90 {
        return "â° Lembre-se de agendar suas fÃ©rias em breve."
    }
    return "VocÃª tem bastante tempo para planejar."
}

func getBankBalanceStatus(minutes int) string {
    if minutes > 0 {
        return "positivo"
    } else if minutes < 0 {
        return "negativo"
    }
    return "zerado"
}

func getBankAdvice(minutes int) string {
    if minutes > 480 { // > 8h
        return "ğŸ’¡ VocÃª pode compensar essas horas ou receber como hora extra."
    } else if minutes < -480 { // < -8h
        return "âš ï¸ AtenÃ§Ã£o ao saldo negativo. Converse com seu gestor sobre compensaÃ§Ã£o."
    }
    return "Seu banco de horas estÃ¡ equilibrado! ğŸ‘"
}

func abs(n int) int {
    if n < 0 {
        return -n
    }
    return n
}
```

### Atualizar o ChatService

```go
// services/chat_service.go
func (s *ChatService) GenerateResponse(userID string, req models.ChatRequest) (*models.ChatResponse, error) {
    ctx := context.Background()

    // Busca contexto completo do usuÃ¡rio
    systemPrompt := s.getSystemPromptWithContext(userID)

    // ConstrÃ³i mensagens
    messages := []azopenai.ChatRequestMessageClassification{
        &azopenai.ChatRequestSystemMessage{
            Content: &systemPrompt,
        },
    }

    // Adiciona histÃ³rico
    if req.ConversationID != "" {
        history := s.getConversationHistory(req.ConversationID, 10)
        for _, msg := range history {
            if msg.Role == "user" {
                messages = append(messages, &azopenai.ChatRequestUserMessage{
                    Content: azopenai.NewChatRequestUserMessageContent(msg.Content),
                })
            } else if msg.Role == "assistant" {
                messages = append(messages, &azopenai.ChatRequestAssistantMessage{
                    Content: &msg.Content,
                })
            }
        }
    }

    // Mensagem atual
    messages = append(messages, &azopenai.ChatRequestUserMessage{
        Content: azopenai.NewChatRequestUserMessageContent(req.Message),
    })

    // Chama Azure OpenAI
    deployment := os.Getenv("AZURE_OPENAI_DEPLOYMENT")
    resp, err := config.OpenAIClient.GetChatCompletions(ctx, azopenai.ChatCompletionsOptions{
        Messages:       messages,
        DeploymentName: &deployment,
        MaxTokens:      toPtr(int32(800)),
        Temperature:    toPtr(float32(0.7)),
    }, nil)

    if err != nil {
        return nil, fmt.Errorf("erro ao chamar OpenAI: %w", err)
    }

    // Extrai resposta
    content := *resp.Choices[0].Message.Content
    tokensUsed := int(*resp.Usage.TotalTokens)

    // Salva conversa
    conversationID := req.ConversationID
    if conversationID == "" {
        conversationID = uuid.New().String()
        s.createConversation(userID, conversationID, req.Message)
    }

    s.saveMessage(conversationID, "user", req.Message, 0)
    s.saveMessage(conversationID, "assistant", content, tokensUsed)

    return &models.ChatResponse{
        ConversationID: conversationID,
        Message:        content,
        TokensUsed:     tokensUsed,
    }, nil
}
```

### Exemplo de Conversa Real

```
UsuÃ¡rio: "Quantas fÃ©rias eu tenho?"

Frappy IA: "VocÃª tem 30 dias de fÃ©rias disponÃ­veis! ğŸ“…
Seu perÃ­odo aquisitivo Ã© 01/03/2023 a 28/02/2024 e vocÃª
precisa usar atÃ© 28/02/2025. VocÃª tem bastante tempo para planejar.

Quer que eu te ajude a agendar suas fÃ©rias?"

---

UsuÃ¡rio: "Como estÃ¡ meu banco de horas?"

Frappy IA: "Seu banco de horas estÃ¡ positivo com 6h 30min! ğŸ’š

VocÃª trabalhou 182h 30min este mÃªs e o esperado era 176h.

ğŸ’¡ VocÃª pode compensar essas horas ou receber como hora extra.
Quer saber mais sobre as opÃ§Ãµes?"

---

UsuÃ¡rio: "Qual foi meu Ãºltimo salÃ¡rio?"

Frappy IA: "Seu Ãºltimo holerite foi de 12/2024:

ğŸ’° SalÃ¡rio lÃ­quido: R$ 4.205,98

Detalhes:
- SalÃ¡rio bruto: R$ 5.654,55
- Descontos: R$ 1.448,57

VocÃª ganhou R$ 50.471,76 no ano atÃ© agora.

Quer ver o detalhamento completo do holerite?"
```

---

## ğŸ”§ Function Calling (EstratÃ©gia 2)

### Conceito

Permitir que a IA **chame funÃ§Ãµes** do backend para buscar dados sob demanda.

### Vantagens

- âœ… Mais eficiente (sÃ³ busca dados quando necessÃ¡rio)
- âœ… Reduz tamanho do prompt (menos tokens = menor custo)
- âœ… IA decide quando precisa de dados
- âœ… Pode executar aÃ§Ãµes (solicitar fÃ©rias, etc)

### ImplementaÃ§Ã£o

```go
// services/chat_functions.go
package services

import (
    "encoding/json"
    "fmt"
    "github.com/Azure/azure-sdk-for-go/sdk/ai/azopenai"
)

// Define funÃ§Ãµes disponÃ­veis para a IA
func (s *ChatService) GetAvailableFunctions() []azopenai.FunctionDefinition {
    return []azopenai.FunctionDefinition{
        // 1. Consultar fÃ©rias
        {
            Name:        toPtr("get_vacation_balance"),
            Description: toPtr("Consulta o saldo de fÃ©rias do usuÃ¡rio, perÃ­odo aquisitivo e prazo"),
            Parameters: map[string]interface{}{
                "type":       "object",
                "properties": map[string]interface{}{},
            },
        },

        // 2. Consultar banco de horas
        {
            Name:        toPtr("get_hour_bank"),
            Description: toPtr("Consulta o banco de horas do usuÃ¡rio no mÃªs atual"),
            Parameters: map[string]interface{}{
                "type":       "object",
                "properties": map[string]interface{}{},
            },
        },

        // 3. Consultar holerite
        {
            Name:        toPtr("get_last_payroll"),
            Description: toPtr("Consulta o Ãºltimo holerite do usuÃ¡rio"),
            Parameters: map[string]interface{}{
                "type":       "object",
                "properties": map[string]interface{}{},
            },
        },

        // 4. Listar cursos disponÃ­veis
        {
            Name:        toPtr("list_available_courses"),
            Description: toPtr("Lista cursos disponÃ­veis para o usuÃ¡rio"),
            Parameters: map[string]interface{}{
                "type": "object",
                "properties": map[string]interface{}{
                    "category": map[string]string{
                        "type":        "string",
                        "description": "Categoria do curso (opcional)",
                    },
                },
            },
        },

        // 5. Solicitar fÃ©rias
        {
            Name:        toPtr("request_vacation"),
            Description: toPtr("Solicita fÃ©rias para o usuÃ¡rio"),
            Parameters: map[string]interface{}{
                "type": "object",
                "properties": map[string]interface{}{
                    "start_date": map[string]string{
                        "type":        "string",
                        "description": "Data de inÃ­cio no formato YYYY-MM-DD",
                    },
                    "days": map[string]string{
                        "type":        "number",
                        "description": "NÃºmero de dias de fÃ©rias",
                    },
                },
                "required": []string{"start_date", "days"},
            },
        },

        // 6. Registrar ponto
        {
            Name:        toPtr("clock_punch"),
            Description: toPtr("Registra ponto do usuÃ¡rio"),
            Parameters: map[string]interface{}{
                "type": "object",
                "properties": map[string]interface{}{
                    "type": map[string]interface{}{
                        "type":        "string",
                        "description": "Tipo de registro: entrada, saida, pausa_inicio, pausa_fim",
                        "enum":        []string{"entrada", "saida", "pausa_inicio", "pausa_fim"},
                    },
                },
                "required": []string{"type"},
            },
        },

        // 7. Buscar polÃ­ticas da empresa
        {
            Name:        toPtr("search_policies"),
            Description: toPtr("Busca polÃ­ticas e regras da empresa"),
            Parameters: map[string]interface{}{
                "type": "object",
                "properties": map[string]interface{}{
                    "query": map[string]string{
                        "type":        "string",
                        "description": "Termo de busca (ex: home office, dress code)",
                    },
                },
                "required": []string{"query"},
            },
        },
    }
}
```

// Executar funÃ§Ã£o chamada pela IA
func (s *ChatService) ExecuteFunction(userID, functionName, arguments string) (string, error) {
    switch functionName {
    case "get_vacation_balance":
        return s.executeGetVacationBalance(userID)

    case "get_hour_bank":
        return s.executeGetHourBank(userID)

    case "get_last_payroll":
        return s.executeGetLastPayroll(userID)

    case "list_available_courses":
        var params struct {
            Category string `json:"category"`
        }
        json.Unmarshal([]byte(arguments), &params)
        return s.executeListCourses(userID, params.Category)

    case "request_vacation":
        var params struct {
            StartDate string `json:"start_date"`
            Days      int    `json:"days"`
        }
        json.Unmarshal([]byte(arguments), &params)
        return s.executeRequestVacation(userID, params.StartDate, params.Days)

    case "clock_punch":
        var params struct {
            Type string `json:"type"`
        }
        json.Unmarshal([]byte(arguments), &params)
        return s.executeClockPunch(userID, params.Type)

    case "search_policies":
        var params struct {
            Query string `json:"query"`
        }
        json.Unmarshal([]byte(arguments), &params)
        return s.executeSearchPolicies(params.Query)

    default:
        return "", fmt.Errorf("funÃ§Ã£o nÃ£o encontrada: %s", functionName)
    }
}

// ImplementaÃ§Ãµes das funÃ§Ãµes

func (s *ChatService) executeGetVacationBalance(userID string) (string, error) {
    balance := getVacationBalance(userID)
    period := getVacationPeriod(userID)
    deadline := getVacationDeadline(userID)

    result := map[string]interface{}{
        "balance":  balance,
        "period":   period,
        "deadline": deadline.Format("2006-01-02"),
    }

    jsonResult, _ := json.Marshal(result)
    return string(jsonResult), nil
}

func (s *ChatService) executeGetHourBank(userID string) (string, error) {
    monthHours := getMonthWorkedHours(userID)
    expectedHours := getExpectedHours(userID)
    bankBalance := getHourBankBalance(userID)

    result := map[string]interface{}{
        "worked_hours":   monthHours,
        "expected_hours": expectedHours,
        "bank_balance":   bankBalance,
        "status":         getBankBalanceStatus(bankBalance),
    }

    jsonResult, _ := json.Marshal(result)
    return string(jsonResult), nil
}

func (s *ChatService) executeGetLastPayroll(userID string) (string, error) {
    payroll := getLastPayroll(userID)

    result := map[string]interface{}{
        "month":        payroll.Month.Format("2006-01"),
        "gross_salary": payroll.GrossSalary,
        "net_salary":   payroll.NetSalary,
        "inss":         payroll.INSS,
        "irrf":         payroll.IRRF,
        "overtime":     payroll.Overtime,
    }

    jsonResult, _ := json.Marshal(result)
    return string(jsonResult), nil
}

func (s *ChatService) executeListCourses(userID, category string) (string, error) {
    user := getUserByID(userID)
    courses := getAvailableCourses(user.Department)

    if category != "" {
        courses = filterCoursesByCategory(courses, category)
    }

    result := map[string]interface{}{
        "courses": courses,
        "count":   len(courses),
    }

    jsonResult, _ := json.Marshal(result)
    return string(jsonResult), nil
}

func (s *ChatService) executeRequestVacation(userID, startDate string, days int) (string, error) {
    err := createVacationRequest(userID, startDate, days)

    if err != nil {
        return fmt.Sprintf(`{"success": false, "error": "%s"}`, err.Error()), nil
    }

    return `{"success": true, "message": "FÃ©rias solicitadas com sucesso! Aguarde aprovaÃ§Ã£o do gestor."}`, nil
}

func (s *ChatService) executeClockPunch(userID, punchType string) (string, error) {
    entry, err := createClockEntry(userID, punchType)

    if err != nil {
        return fmt.Sprintf(`{"success": false, "error": "%s"}`, err.Error()), nil
    }

    return fmt.Sprintf(`{"success": true, "type": "%s", "timestamp": "%s"}`,
        entry.Type,
        entry.Timestamp.Format("15:04"),
    ), nil
}

func (s *ChatService) executeSearchPolicies(query string) (string, error) {
    policies := searchCompanyPolicies(query)

    result := map[string]interface{}{
        "policies": policies,
        "count":    len(policies),
    }

    jsonResult, _ := json.Marshal(result)
    return string(jsonResult), nil
}
```

// Atualizar GenerateResponse para suportar function calling
func (s *ChatService) GenerateResponseWithFunctions(userID string, req models.ChatRequest) (*models.ChatResponse, error) {
    ctx := context.Background()

    // System prompt bÃ¡sico (sem dados pesados)
    systemPrompt := `VocÃª Ã© o Frappy IA, assistente do FrappYOU.

VocÃª tem acesso a funÃ§Ãµes para buscar dados do sistema:
- get_vacation_balance: consultar fÃ©rias
- get_hour_bank: consultar banco de horas
- get_last_payroll: consultar holerite
- list_available_courses: listar cursos
- request_vacation: solicitar fÃ©rias
- clock_punch: registrar ponto
- search_policies: buscar polÃ­ticas

Use essas funÃ§Ãµes quando o usuÃ¡rio perguntar sobre esses tÃ³picos.
Responda sempre em portuguÃªs do Brasil.`

    // ConstrÃ³i mensagens
    messages := []azopenai.ChatRequestMessageClassification{
        &azopenai.ChatRequestSystemMessage{
            Content: &systemPrompt,
        },
    }

    // Adiciona histÃ³rico
    if req.ConversationID != "" {
        history := s.getConversationHistory(req.ConversationID, 10)
        for _, msg := range history {
            if msg.Role == "user" {
                messages = append(messages, &azopenai.ChatRequestUserMessage{
                    Content: azopenai.NewChatRequestUserMessageContent(msg.Content),
                })
            } else if msg.Role == "assistant" {
                messages = append(messages, &azopenai.ChatRequestAssistantMessage{
                    Content: &msg.Content,
                })
            }
        }
    }

    // Mensagem atual
    messages = append(messages, &azopenai.ChatRequestUserMessage{
        Content: azopenai.NewChatRequestUserMessageContent(req.Message),
    })

    // Chama OpenAI com functions
    deployment := os.Getenv("AZURE_OPENAI_DEPLOYMENT")
    functions := s.GetAvailableFunctions()

    resp, err := config.OpenAIClient.GetChatCompletions(ctx, azopenai.ChatCompletionsOptions{
        Messages:       messages,
        DeploymentName: &deployment,
        Functions:      functions,
        MaxTokens:      toPtr(int32(800)),
        Temperature:    toPtr(float32(0.7)),
    }, nil)

    if err != nil {
        return nil, fmt.Errorf("erro ao chamar OpenAI: %w", err)
    }

    choice := resp.Choices[0]

    // Verifica se a IA quer chamar uma funÃ§Ã£o
    if choice.FinishReason != nil && *choice.FinishReason == "function_call" {
        functionCall := choice.Message.FunctionCall

        // Executa a funÃ§Ã£o
        functionResult, err := s.ExecuteFunction(
            userID,
            *functionCall.Name,
            *functionCall.Arguments,
        )

        if err != nil {
            return nil, fmt.Errorf("erro ao executar funÃ§Ã£o: %w", err)
        }

        // Adiciona resultado da funÃ§Ã£o Ã s mensagens
        messages = append(messages, &azopenai.ChatRequestAssistantMessage{
            Content:      choice.Message.Content,
            FunctionCall: functionCall,
        })

        messages = append(messages, &azopenai.ChatRequestFunctionMessage{
            Name:    functionCall.Name,
            Content: &functionResult,
        })

        // Segunda chamada para a IA processar o resultado
        resp2, err := config.OpenAIClient.GetChatCompletions(ctx, azopenai.ChatCompletionsOptions{
            Messages:       messages,
            DeploymentName: &deployment,
            MaxTokens:      toPtr(int32(800)),
            Temperature:    toPtr(float32(0.7)),
        }, nil)

        if err != nil {
            return nil, fmt.Errorf("erro na segunda chamada: %w", err)
        }

        content := *resp2.Choices[0].Message.Content
        tokensUsed := int(*resp.Usage.TotalTokens + *resp2.Usage.TotalTokens)

        // Salva conversa
        conversationID := req.ConversationID
        if conversationID == "" {
            conversationID = uuid.New().String()
            s.createConversation(userID, conversationID, req.Message)
        }

        s.saveMessage(conversationID, "user", req.Message, 0)
        s.saveMessage(conversationID, "assistant", content, tokensUsed)

        return &models.ChatResponse{
            ConversationID: conversationID,
            Message:        content,
            TokensUsed:     tokensUsed,
        }, nil
    }

    // Resposta normal (sem function call)
    content := *choice.Message.Content
    tokensUsed := int(*resp.Usage.TotalTokens)

    conversationID := req.ConversationID
    if conversationID == "" {
        conversationID = uuid.New().String()
        s.createConversation(userID, conversationID, req.Message)
    }

    s.saveMessage(conversationID, "user", req.Message, 0)
    s.saveMessage(conversationID, "assistant", content, tokensUsed)

    return &models.ChatResponse{
        ConversationID: conversationID,
        Message:        content,
        TokensUsed:     tokensUsed,
    }, nil
}
```

### Exemplo de Conversa com Function Calling

```
UsuÃ¡rio: "Quantas fÃ©rias eu tenho?"

[IA decide chamar get_vacation_balance()]
[Backend executa funÃ§Ã£o e retorna: {"balance": 30, "period": "01/03/2023 a 28/02/2024", "deadline": "2025-02-28"}]
[IA processa resultado]

Frappy IA: "VocÃª tem 30 dias de fÃ©rias disponÃ­veis! ğŸ“…
Seu perÃ­odo aquisitivo Ã© de 01/03/2023 a 28/02/2024 e vocÃª
precisa usar atÃ© 28/02/2025. Quer que eu te ajude a agendar?"

---

UsuÃ¡rio: "Sim, quero tirar 15 dias a partir de 10/01/2025"

[IA decide chamar request_vacation("2025-01-10", 15)]
[Backend cria solicitaÃ§Ã£o]

Frappy IA: "Pronto! âœ… Suas fÃ©rias foram solicitadas:
- PerÃ­odo: 10/01/2025 a 24/01/2025 (15 dias)
- Status: Aguardando aprovaÃ§Ã£o do gestor

VocÃª receberÃ¡ uma notificaÃ§Ã£o quando for aprovado!"
```

---

## ğŸ“š RAG - Base de Conhecimento (EstratÃ©gia 3)

### Conceito

Criar uma base de conhecimento com documentos da empresa e buscar informaÃ§Ãµes relevantes antes de responder.

### Casos de Uso

- PolÃ­ticas da empresa
- FAQs
- Manuais e procedimentos
- HistÃ³rico de conversas similares

### ImplementaÃ§Ã£o

```go
// models/knowledge_base.go
package models

type KnowledgeDocument struct {
    ID          string    `json:"id"`
    Title       string    `json:"title"`
    Content     string    `json:"content"`
    Category    string    `json:"category"` // policy, faq, manual
    Tags        []string  `json:"tags"`
    CreatedAt   time.Time `json:"created_at"`
    UpdatedAt   time.Time `json:"updated_at"`
}

// services/rag_service.go
package services

type RAGService struct{}

func NewRAGService() *RAGService {
    return &RAGService{}
}

// Buscar documentos relevantes
func (r *RAGService) SearchRelevantDocuments(query string, limit int) ([]models.KnowledgeDocument, error) {
    // ImplementaÃ§Ã£o simples com busca de texto
    // Em produÃ§Ã£o, usar embeddings + vector database

    docs := []models.KnowledgeDocument{}

    // Busca em polÃ­ticas
    policies := r.searchInCategory(query, "policy", limit/3)
    docs = append(docs, policies...)

    // Busca em FAQs
    faqs := r.searchInCategory(query, "faq", limit/3)
    docs = append(docs, faqs...)

    // Busca em manuais
    manuals := r.searchInCategory(query, "manual", limit/3)
    docs = append(docs, manuals...)

    return docs, nil
}

func (r *RAGService) searchInCategory(query string, category string, limit int) []models.KnowledgeDocument {
    // Busca simples por palavras-chave
    keywords := extractKeywords(query)

    var docs []models.KnowledgeDocument
    db.Where("category = ?", category).Find(&docs)

    // Ranqueia por relevÃ¢ncia
    scored := []struct {
        doc   models.KnowledgeDocument
        score int
    }{}

    for _, doc := range docs {
        score := 0
        content := strings.ToLower(doc.Title + " " + doc.Content)

        for _, keyword := range keywords {
            if strings.Contains(content, keyword) {
                score++
            }
        }

        if score > 0 {
            scored = append(scored, struct {
                doc   models.KnowledgeDocument
                score int
            }{doc, score})
        }
    }

    // Ordena por score
    sort.Slice(scored, func(i, j int) bool {
        return scored[i].score > scored[j].score
    })

    // Retorna top N
    result := []models.KnowledgeDocument{}
    for i := 0; i < len(scored) && i < limit; i++ {
        result = append(result, scored[i].doc)
    }

    return result
}

func extractKeywords(query string) []string {
    // Remove stopwords e extrai palavras-chave
    stopwords := map[string]bool{
        "o": true, "a": true, "de": true, "para": true,
        "com": true, "em": true, "Ã©": true, "como": true,
    }

    words := strings.Fields(strings.ToLower(query))
    keywords := []string{}

    for _, word := range words {
        if !stopwords[word] && len(word) > 3 {
            keywords = append(keywords, word)
        }
    }

    return keywords
}
```

// Integrar RAG no ChatService
func (s *ChatService) GenerateResponseWithRAG(userID string, req models.ChatRequest) (*models.ChatResponse, error) {
    ctx := context.Background()
    ragService := NewRAGService()

    // Busca documentos relevantes
    relevantDocs, _ := ragService.SearchRelevantDocuments(req.Message, 3)

    // System prompt com contexto do usuÃ¡rio
    systemPrompt := s.getBasicSystemPrompt(userID)

    // Adiciona documentos relevantes ao contexto
    if len(relevantDocs) > 0 {
        systemPrompt += "\n\n## DOCUMENTOS RELEVANTES\n\n"

        for i, doc := range relevantDocs {
            systemPrompt += fmt.Sprintf("### Documento %d: %s\n\n%s\n\n",
                i+1,
                doc.Title,
                doc.Content,
            )
        }

        systemPrompt += "Use as informaÃ§Ãµes acima para responder a pergunta do usuÃ¡rio.\n"
    }

    // ConstrÃ³i mensagens
    messages := []azopenai.ChatRequestMessageClassification{
        &azopenai.ChatRequestSystemMessage{
            Content: &systemPrompt,
        },
    }

    // Adiciona histÃ³rico
    if req.ConversationID != "" {
        history := s.getConversationHistory(req.ConversationID, 10)
        for _, msg := range history {
            if msg.Role == "user" {
                messages = append(messages, &azopenai.ChatRequestUserMessage{
                    Content: azopenai.NewChatRequestUserMessageContent(msg.Content),
                })
            } else if msg.Role == "assistant" {
                messages = append(messages, &azopenai.ChatRequestAssistantMessage{
                    Content: &msg.Content,
                })
            }
        }
    }

    // Mensagem atual
    messages = append(messages, &azopenai.ChatRequestUserMessage{
        Content: azopenai.NewChatRequestUserMessageContent(req.Message),
    })

    // Chama Azure OpenAI
    deployment := os.Getenv("AZURE_OPENAI_DEPLOYMENT")
    resp, err := config.OpenAIClient.GetChatCompletions(ctx, azopenai.ChatCompletionsOptions{
        Messages:       messages,
        DeploymentName: &deployment,
        MaxTokens:      toPtr(int32(1000)), // Mais tokens para processar documentos
        Temperature:    toPtr(float32(0.7)),
    }, nil)

    if err != nil {
        return nil, fmt.Errorf("erro ao chamar OpenAI: %w", err)
    }

    content := *resp.Choices[0].Message.Content
    tokensUsed := int(*resp.Usage.TotalTokens)

    // Salva conversa
    conversationID := req.ConversationID
    if conversationID == "" {
        conversationID = uuid.New().String()
        s.createConversation(userID, conversationID, req.Message)
    }

    s.saveMessage(conversationID, "user", req.Message, 0)
    s.saveMessage(conversationID, "assistant", content, tokensUsed)

    return &models.ChatResponse{
        ConversationID: conversationID,
        Message:        content,
        TokensUsed:     tokensUsed,
    }, nil
}
```

### Exemplo de Conversa com RAG

```
UsuÃ¡rio: "Como funciona o home office?"

[Sistema busca documentos sobre "home office"]
[Encontra: "PolÃ­tica de Home Office", "FAQ - Trabalho Remoto"]
[Injeta documentos no prompt]

Frappy IA: "A polÃ­tica de home office da empresa funciona assim:

ğŸ  **Modalidades:**
- HÃ­brido: 2 dias/semana em casa (terÃ§a e quinta)
- Remoto: AprovaÃ§Ã£o do gestor + RH necessÃ¡ria

ğŸ“‹ **Requisitos:**
- Internet mÃ­nima: 10 Mbps
- EspaÃ§o adequado de trabalho
- Disponibilidade no horÃ¡rio comercial (9h-18h)

â° **Registro de Ponto:**
- ObrigatÃ³rio mesmo em home office
- Usar o sistema normalmente

ğŸ“ **ReuniÃµes:**
- CÃ¢mera ligada em reuniÃµes de equipe
- Responder mensagens em atÃ© 30 minutos

Quer solicitar home office? Posso te ajudar com o processo!"
```

### Criar Base de Conhecimento

```sql
-- Tabela de documentos
CREATE TABLE knowledge_documents (
    id VARCHAR(36) PRIMARY KEY,
    title NVARCHAR(200) NOT NULL,
    content NVARCHAR(MAX) NOT NULL,
    category VARCHAR(50) NOT NULL, -- policy, faq, manual
    tags NVARCHAR(500), -- JSON array
    created_at DATETIME2 DEFAULT GETDATE(),
    updated_at DATETIME2 DEFAULT GETDATE()
);

-- Ãndices para busca
CREATE INDEX idx_knowledge_category ON knowledge_documents(category);
CREATE FULLTEXT INDEX idx_knowledge_content ON knowledge_documents(title, content);

-- Inserir documentos de exemplo
INSERT INTO knowledge_documents (id, title, content, category, tags) VALUES
('1', 'PolÃ­tica de Home Office',
'A empresa permite trabalho remoto nas seguintes modalidades:
1. HÃ­brido: 2 dias por semana (terÃ§a e quinta)
2. Remoto total: Mediante aprovaÃ§Ã£o do gestor e RH

Requisitos:
- Internet mÃ­nima de 10 Mbps
- EspaÃ§o adequado de trabalho
- Disponibilidade no horÃ¡rio comercial

O registro de ponto Ã© obrigatÃ³rio mesmo em home office.',
'policy',
'["home office", "trabalho remoto", "hÃ­brido"]'),

('2', 'Como solicitar fÃ©rias',
'Para solicitar fÃ©rias:
1. Acesse o sistema FrappYOU
2. VÃ¡ em FÃ©rias > Solicitar
3. Escolha as datas
4. Aguarde aprovaÃ§Ã£o do gestor

Regras:
- MÃ­nimo 5 dias corridos
- Avisar com 30 dias de antecedÃªncia
- NÃ£o pode ter solicitaÃ§Ã£o pendente',
'faq',
'["fÃ©rias", "solicitaÃ§Ã£o", "aprovaÃ§Ã£o"]');
```

---

## âš¡ Cache Inteligente (OtimizaÃ§Ã£o)

### Problema

Buscar dados do banco a cada mensagem Ã© custoso e lento.

### SoluÃ§Ã£o

Implementar cache com Redis para dados que mudam pouco.

### ImplementaÃ§Ã£o

```go
// services/chat_cache.go
package services

import (
    "context"
    "encoding/json"
    "fmt"
    "time"

    "github.com/go-redis/redis/v8"
)

type ChatCache struct {
    client *redis.Client
}

func NewChatCache() *ChatCache {
    client := redis.NewClient(&redis.Options{
        Addr: os.Getenv("REDIS_URL"),
    })

    return &ChatCache{client: client}
}

// Cache de contexto do usuÃ¡rio
func (c *ChatCache) GetUserContext(userID string) (*ChatContext, error) {
    ctx := context.Background()
    key := fmt.Sprintf("chat:context:%s", userID)

    val, err := c.client.Get(ctx, key).Result()
    if err == redis.Nil {
        return nil, nil // Cache miss
    }
    if err != nil {
        return nil, err
    }

    var context ChatContext
    err = json.Unmarshal([]byte(val), &context)
    return &context, err
}

func (c *ChatCache) SetUserContext(userID string, context *ChatContext, ttl time.Duration) error {
    ctx := context.Background()
    key := fmt.Sprintf("chat:context:%s", userID)

    data, err := json.Marshal(context)
    if err != nil {
        return err
    }

    return c.client.Set(ctx, key, data, ttl).Err()
}

// Cache de respostas comuns
func (c *ChatCache) GetCachedResponse(query string) (string, error) {
    ctx := context.Background()
    key := fmt.Sprintf("chat:response:%s", hashQuery(query))

    return c.client.Get(ctx, key).Result()
}

func (c *ChatCache) SetCachedResponse(query, response string, ttl time.Duration) error {
    ctx := context.Background()
    key := fmt.Sprintf("chat:response:%s", hashQuery(query))

    return c.client.Set(ctx, key, response, ttl).Err()
}

func hashQuery(query string) string {
    // Normaliza e cria hash da query
    normalized := strings.ToLower(strings.TrimSpace(query))
    hash := sha256.Sum256([]byte(normalized))
    return hex.EncodeToString(hash[:])
}
```

### Atualizar ChatService com Cache

```go
func (s *ChatService) GenerateResponseWithCache(userID string, req models.ChatRequest) (*models.ChatResponse, error) {
    cache := NewChatCache()

    // 1. Tenta buscar resposta em cache
    if cachedResponse, err := cache.GetCachedResponse(req.Message); err == nil {
        return &models.ChatResponse{
            Message:    cachedResponse,
            TokensUsed: 0, // NÃ£o usou tokens
        }, nil
    }

    // 2. Tenta buscar contexto em cache
    context, err := cache.GetUserContext(userID)
    if err != nil || context == nil {
        // Cache miss - busca do banco
        context, err = s.GetUserContext(userID)
        if err != nil {
            return nil, err
        }

        // Salva em cache (5 minutos)
        cache.SetUserContext(userID, context, 5*time.Minute)
    }

    // 3. Gera resposta normalmente
    response, err := s.GenerateResponse(userID, req)
    if err != nil {
        return nil, err
    }

    // 4. Cacheia respostas para perguntas comuns
    if isCommonQuestion(req.Message) {
        cache.SetCachedResponse(req.Message, response.Message, 1*time.Hour)
    }

    return response, nil
}

func isCommonQuestion(message string) bool {
    commonPatterns := []string{
        "quantas fÃ©rias",
        "banco de horas",
        "Ãºltimo salÃ¡rio",
        "como funciona",
        "polÃ­tica de",
    }

    lower := strings.ToLower(message)
    for _, pattern := range commonPatterns {
        if strings.Contains(lower, pattern) {
            return true
        }
    }

    return false
}
```

### Configurar Redis

```bash
# docker-compose.yml
version: '3.8'
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  redis_data:
```

```bash
# backend/.env
REDIS_URL=localhost:6379
```

```go
// go.mod
require github.com/go-redis/redis/v8 v8.11.5
```

---

## ğŸ¯ EstratÃ©gia HÃ­brida (Recomendado)

### Combinar as 3 EstratÃ©gias

Para melhor resultado, use todas as estratÃ©gias juntas:

```go
// services/chat_service.go
func (s *ChatService) GenerateSmartResponse(userID string, req models.ChatRequest) (*models.ChatResponse, error) {
    cache := NewChatCache()
    ragService := NewRAGService()

    // 1. CACHE: Tenta buscar resposta em cache
    if cachedResponse, err := cache.GetCachedResponse(req.Message); err == nil {
        log.Printf("âœ… Cache hit para: %s", req.Message)
        return &models.ChatResponse{
            Message:    cachedResponse,
            TokensUsed: 0,
        }, nil
    }

    // 2. CONTEXT INJECTION: Busca contexto do usuÃ¡rio (com cache)
    context, err := cache.GetUserContext(userID)
    if err != nil || context == nil {
        context, err = s.GetUserContext(userID)
        if err != nil {
            return nil, err
        }
        cache.SetUserContext(userID, context, 5*time.Minute)
    }

    // 3. RAG: Busca documentos relevantes
    relevantDocs, _ := ragService.SearchRelevantDocuments(req.Message, 3)

    // 4. Monta system prompt com contexto + documentos
    systemPrompt := s.buildHybridSystemPrompt(context, relevantDocs)

    // 5. FUNCTION CALLING: Define funÃ§Ãµes disponÃ­veis
    functions := s.GetAvailableFunctions()

    // 6. Chama Azure OpenAI
    ctx := context.Background()
    messages := s.buildMessages(systemPrompt, req)

    deployment := os.Getenv("AZURE_OPENAI_DEPLOYMENT")
    resp, err := config.OpenAIClient.GetChatCompletions(ctx, azopenai.ChatCompletionsOptions{
        Messages:       messages,
        DeploymentName: &deployment,
        Functions:      functions,
        MaxTokens:      toPtr(int32(1000)),
        Temperature:    toPtr(float32(0.7)),
    }, nil)

    if err != nil {
        return nil, fmt.Errorf("erro ao chamar OpenAI: %w", err)
    }

    choice := resp.Choices[0]

    // 7. Processa function calling se necessÃ¡rio
    if choice.FinishReason != nil && *choice.FinishReason == "function_call" {
        return s.handleFunctionCall(userID, req, messages, choice)
    }

    // 8. Resposta normal
    content := *choice.Message.Content
    tokensUsed := int(*resp.Usage.TotalTokens)

    // 9. Cacheia se for pergunta comum
    if isCommonQuestion(req.Message) {
        cache.SetCachedResponse(req.Message, content, 1*time.Hour)
    }

    // 10. Salva conversa
    conversationID := req.ConversationID
    if conversationID == "" {
        conversationID = uuid.New().String()
        s.createConversation(userID, conversationID, req.Message)
    }

    s.saveMessage(conversationID, "user", req.Message, 0)
    s.saveMessage(conversationID, "assistant", content, tokensUsed)

    return &models.ChatResponse{
        ConversationID: conversationID,
        Message:        content,
        TokensUsed:     tokensUsed,
    }, nil
}

func (s *ChatService) buildHybridSystemPrompt(context *ChatContext, docs []models.KnowledgeDocument) string {
    prompt := fmt.Sprintf(`VocÃª Ã© o Frappy IA, assistente do FrappYOU.

## DADOS DO COLABORADOR
- Nome: %s
- Cargo: %s
- Departamento: %s
- FÃ©rias disponÃ­veis: %d dias
- Banco de horas: %s (%dh %dmin)
`,
        context.UserData.Name,
        context.UserData.Position,
        context.UserData.Department,
        context.VacationData.Balance,
        getBankBalanceStatus(context.ClockData.BankBalance),
        abs(context.ClockData.BankBalance)/60,
        abs(context.ClockData.BankBalance)%60,
    )

    // Adiciona documentos relevantes
    if len(docs) > 0 {
        prompt += "\n## DOCUMENTOS RELEVANTES\n\n"
        for i, doc := range docs {
            prompt += fmt.Sprintf("### %d. %s\n%s\n\n", i+1, doc.Title, doc.Content)
        }
    }

    prompt += `
## INSTRUÃ‡Ã•ES
1. Use os dados acima para responder
2. Se precisar de mais dados, use as funÃ§Ãµes disponÃ­veis
3. Seja especÃ­fico e preciso
4. Use emojis moderadamente
5. Responda em portuguÃªs do Brasil
`

    return prompt
}
```

### Fluxo Completo

```
UsuÃ¡rio: "Quantas fÃ©rias tenho?"
    â†“
1. Verifica cache â†’ Miss
    â†“
2. Busca contexto do usuÃ¡rio (cache ou DB)
    â†“
3. Busca documentos sobre fÃ©rias (RAG)
    â†“
4. Monta prompt com contexto + documentos
    â†“
5. Define funÃ§Ãµes disponÃ­veis
    â†“
6. Chama Azure OpenAI
    â†“
7. IA decide: usar dados do prompt ou chamar funÃ§Ã£o?
    â†“
8. Gera resposta
    â†“
9. Cacheia resposta (1 hora)
    â†“
10. Retorna para usuÃ¡rio
```

---

## ğŸ“Š ComparaÃ§Ã£o das EstratÃ©gias

| EstratÃ©gia | Vantagens | Desvantagens | Quando Usar |
|------------|-----------|--------------|-------------|
| **Context Injection** | âœ… Simples<br>âœ… Dados sempre atualizados<br>âœ… NÃ£o precisa function calling | âŒ Prompt grande<br>âŒ Mais tokens<br>âŒ Busca tudo sempre | Dados pequenos e frequentes |
| **Function Calling** | âœ… Eficiente<br>âœ… Busca sob demanda<br>âœ… Pode executar aÃ§Ãµes | âŒ Mais complexo<br>âŒ 2 chamadas Ã  IA<br>âŒ Mais lento | Dados grandes ou aÃ§Ãµes |
| **RAG** | âœ… EscalÃ¡vel<br>âœ… Base de conhecimento<br>âœ… Documentos longos | âŒ Precisa manutenÃ§Ã£o<br>âŒ Busca pode falhar<br>âŒ Complexo | PolÃ­ticas e documentos |
| **Cache** | âœ… Muito rÃ¡pido<br>âœ… Reduz custos<br>âœ… Menos chamadas | âŒ Dados podem ficar velhos<br>âŒ Precisa Redis | Perguntas comuns |

---

## ğŸš€ ImplementaÃ§Ã£o Passo a Passo

### Fase 1: Context Injection (1 semana)

```bash
âœ… Criar GetUserContext()
âœ… Criar getSystemPromptWithContext()
âœ… Testar com dados reais
âœ… Ajustar formataÃ§Ã£o de respostas
```

### Fase 2: Function Calling (2 semanas)

```bash
âœ… Definir funÃ§Ãµes disponÃ­veis
âœ… Implementar ExecuteFunction()
âœ… Atualizar GenerateResponse()
âœ… Testar chamadas de funÃ§Ã£o
âœ… Adicionar mais funÃ§Ãµes (solicitar fÃ©rias, etc)
```

### Fase 3: RAG (2 semanas)

```bash
âœ… Criar tabela knowledge_documents
âœ… Implementar SearchRelevantDocuments()
âœ… Popular base com polÃ­ticas
âœ… Integrar no GenerateResponse()
âœ… Testar busca de documentos
```

### Fase 4: Cache (1 semana)

```bash
âœ… Configurar Redis
âœ… Implementar ChatCache
âœ… Adicionar cache de contexto
âœ… Adicionar cache de respostas
âœ… Monitorar hit rate
```

### Fase 5: HÃ­brido (1 semana)

```bash
âœ… Combinar todas estratÃ©gias
âœ… Otimizar fluxo
âœ… Testes de carga
âœ… Ajustes finais
```

---

## ğŸ’° Impacto nos Custos

### Sem OtimizaÃ§Ã£o

```
100 usuÃ¡rios Ã— 10 msgs/dia Ã— 22 dias = 22.000 msgs/mÃªs
MÃ©dia 1.000 tokens/msg (prompt grande)
22M tokens Ã— $0.045/1K = $990/mÃªs
```

### Com OtimizaÃ§Ã£o (Cache + Function Calling)

```
Cache hit rate: 40% (8.800 msgs)
Restante: 13.200 msgs

Function calling: mÃ©dia 600 tokens/msg
13.2M tokens Ã— $0.045/1K = $594/mÃªs

Economia: $396/mÃªs (40%)
```

---

## ğŸ“ˆ MÃ©tricas para Monitorar

```go
// handlers/chat_metrics.go
func GetChatMetrics(c *fiber.Ctx) error {
    metrics := map[string]interface{}{
        // Performance
        "avg_response_time":    getAvgResponseTime(),
        "cache_hit_rate":       getCacheHitRate(),
        "function_call_rate":   getFunctionCallRate(),

        // Qualidade
        "avg_user_rating":      getAvgUserRating(),
        "helpful_rate":         getHelpfulRate(),
        "error_rate":           getErrorRate(),

        // Custos
        "total_tokens_used":    getTotalTokensUsed(),
        "total_cost":           getTotalCost(),
        "cost_per_user":        getCostPerUser(),

        // Uso
        "total_conversations":  getTotalConversations(),
        "active_users":         getActiveUsers(),
        "most_asked_topics":    getMostAskedTopics(),
    }

    return c.JSON(metrics)
}
```

---

## âœ… Checklist Final

### Backend
- [ ] Context Injection implementado
- [ ] Function Calling implementado
- [ ] RAG implementado
- [ ] Cache implementado
- [ ] EstratÃ©gia hÃ­brida funcionando
- [ ] MÃ©tricas configuradas
- [ ] Logs de auditoria
- [ ] Testes de carga

### Base de Dados
- [ ] Tabela knowledge_documents criada
- [ ] PolÃ­ticas da empresa cadastradas
- [ ] FAQs cadastrados
- [ ] Ãndices criados
- [ ] Redis configurado

### Monitoramento
- [ ] Dashboard de mÃ©tricas
- [ ] Alertas de custo
- [ ] Monitoramento de cache
- [ ] Logs de erros
- [ ] Feedback dos usuÃ¡rios

---

## ğŸ“ PrÃ³ximos Passos

1. **Implementar Context Injection** (mais simples)
2. **Testar com usuÃ¡rios reais**
3. **Adicionar Function Calling** (mais poderoso)
4. **Popular base de conhecimento** (RAG)
5. **Otimizar com cache** (reduzir custos)
6. **Monitorar e ajustar**

---

**Criado para FrappYOU** | Ãšltima atualizaÃ§Ã£o: Dezembro 2024
